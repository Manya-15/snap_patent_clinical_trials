{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747421c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ML SELF CODES\\snaplife\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Fetching patent data for Lens ID: 023-587-103-542-962\n",
      "üìë Found publication number: WO2024/167694A2\n",
      "üîç Using DOCDB number: WO.2024167694.A2\n",
      "üìÑ Found 14 claims\n",
      "üìö Retrieved bibliographic data\n",
      "\n",
      "=== PATENT METADATA ===\n",
      "üìë Source: EPO OPS + Lens.org\n",
      "üîë Publication: WO2024/167694A2\n",
      "üìù Title: PLACENTAL EXTRACELLULAR MATRICES FOR OCULAR DELIVERY OF OPHTHALMIC THERAPEUTIC AGENTS\n",
      "üìñ Abstract: Provided herein are novel and useful pharmaceutical compositions comprising a placenta derived biomaterial and at least one ophthalmic therapeutic agent for treating an ocular disease or condition. ...\n",
      "\n",
      "=== CLAIMS PREVIEW ===\n",
      "Claim 1: WHAT IS CLAIMED IS:...\n",
      "Claim 2: A pharmaceutical composition for treating an ocula...\n",
      "Claim 3: The pharmaceutical composition of Claim 1, wherein...\n",
      "Claim 4: The pharmaceutical composition of Claim 2, wherein...\n",
      "Claim 5: The composition of Claim 2, wherein the JAK inhibi...\n",
      "Claim 6: The pharmaceutical composition of Claim 2, wherein...\n",
      "Claim 7: The pharmaceutical composition of Claim 2, wherein...\n",
      "Claim 8: The pharmaceutical composition of Claim 2, wherein...\n",
      "Claim 9: The pharmaceutical composition of Claim 2, wherein...\n",
      "Claim 10: The pharmaceutical composition of any of Claims 1-...\n",
      "Claim 11: The pharmaceutical composition of any of Claims 1-...\n",
      "Claim 12: The pharmaceutical composition of any of Claims 1-...\n",
      "Claim 13: A method of treating an ocular disease or conditio...\n",
      "Claim 14: The method of Claim 12, wherein the ocular disease...\n",
      "[DEBUG] Normalized sponsor names for search: {'celularity'}\n",
      "[DEBUG] Executing Sponsor Match SQL Query:\n",
      "SELECT s.nct_id, s.official_title, s.start_date, sp.name AS sponsor_name FROM studies AS s JOIN sponsors AS sp ON s.nct_id = sp.nct_id WHERE (lower(name) LIKE '%celularity%');\n",
      "[DEBUG] Sponsor match query returned 17 rows.\n",
      "\n",
      "[DEBUG] Initializing SentenceTransformer model...\n",
      "\n",
      "[DEBUG] Aggregated Patent Text (first 300 chars):\n",
      "PLACENTAL EXTRACELLULAR MATRICES FOR OCULAR DELIVERY OF OPHTHALMIC THERAPEUTIC AGENTS. Provided herein are novel and useful pharmaceutical compositions comprising a placenta derived biomaterial and at least one ophthalmic therapeutic agent for treating an ocular disease or condition.. WHAT IS CLAIME...\n",
      "[DEBUG] Encoding patent text into a vector...\n",
      "\n",
      "[DEBUG] Starting to process and score each candidate trial...\n",
      "\n",
      "--- Processing NCT02264288 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT02264288 (first 300 chars):\n",
      "Efficacy and Safety of Intramuscular PDA-002 in Subjects Who Have Diabetic Foot Ulcer With and Without Peripheral Arterial Disease. A Phase 2 Multicenter, Randomized, Doubleblind, Placebo-Controlled, Dose Range Finding Study to Evaluate the Efficacy and Safety of Intramuscular Injection of Human Pla...\n",
      "[DEBUG] Encoding trial text for NCT02264288...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ML SELF CODES\\snaplife\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Calculated Cosine Similarity Score for NCT02264288: 0.3945\n",
      "\n",
      "--- Processing NCT01440192 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01440192 (first 300 chars):\n",
      "Safety of Intravenous Infusion of Human Placenta-Derived Cells (PDA001) for the Treatment of Adults With Stage II or III Pulmonary Sarcoidosis. A Phase 1B, Multi-Center, Open-Label, Single Dose Study to Evaluate the Safety of Intravenous Infusion of Human Placental-Derived Cells (PDA001) for the Tre...\n",
      "[DEBUG] Encoding trial text for NCT01440192...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01440192: 0.3715\n",
      "\n",
      "--- Processing NCT01859117 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01859117 (first 300 chars):\n",
      "Study of Human Placenta-derived Cells (PDA002) to Evaluate the Safety and Effectiveness in Subjects With PAD and DFU. A Phase 1 Multicenter, Open-Label, Dose-Escalation Study to Evaluate the Safety and Efficacy of Intramuscular Injection of Human Placenta-Derived Cells (PDA-002) in Subjects With Per...\n",
      "[DEBUG] Encoding trial text for NCT01859117...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01859117: 0.4816\n",
      "\n",
      "--- Processing NCT04365101 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT04365101 (first 300 chars):\n",
      "Natural Killer Cell (CYNK-001) Infusions in Adults With COVID-19. A Phase I/II Study of Human Placental Hematopoietic Stem Cell Derived Natural Killer Cells (CYNK-001) for the Treatment of Adults With COVID-19. This study is a Phase 1 / 2 trial to determine the safety and efficacy of CYNK-001, an im...\n",
      "[DEBUG] Encoding trial text for NCT04365101...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT04365101: 0.3675\n",
      "\n",
      "--- Processing NCT05207722 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT05207722 (first 300 chars):\n",
      "CYNK-101 in Combination with Trastuzumab and Pembrolizumab in Patients with Locally Advanced Unresectable or Metastatic HER2-Positive Gastric or Gastroesophageal Junction (G/GEJ) Adenocarcinoma. A Phase I/IIa Open Label, Non-Randomized, Multicenter Study of CYNK-101 in Combination with Trastuzumab a...\n",
      "[DEBUG] Encoding trial text for NCT05207722...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT05207722: 0.2991\n",
      "\n",
      "--- Processing NCT04310592 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT04310592 (first 300 chars):\n",
      "Natural Killer Cell (CYNK-001) Infusions in Adults with AML. A Phase I Multi-dose Study of Human Placental Hematopoietic Stem Cell Derived Natural Killer Cells (CYNK-001) with or Without Recombinant Human Interleukin-2 (rhIL-2) in Adults with Primary or Secondary Acute Myeloid Leukemia (AML) in Morp...\n",
      "[DEBUG] Encoding trial text for NCT04310592...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT04310592: 0.4298\n",
      "\n",
      "--- Processing NCT01155362 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01155362 (first 300 chars):\n",
      "A Multi-Center Study to Evaluate the Safety and Efficacy of Intravenous Infusion of Human Placenta-Derived Cells (PDA001) for the Treatment of Adults With Moderate-to-Severe Crohn's Disease. A Phase 2a, Randomized, Double Blind, Placebo Controlled, Multi-Center Study to Evaluate the Safety and Effic...\n",
      "[DEBUG] Encoding trial text for NCT01155362...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01155362: 0.3728\n",
      "\n",
      "--- Processing NCT04309084 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT04309084 (first 300 chars):\n",
      "Natural Killer Cell (CYNK-001) Infusions in Adults With Multiple Myeloma. A Phase I Study of Human Placental Hematopoietic Stem Cell Derived Natural Killer Cells (CYNK 001) in Multiple Myeloma Patients Following Autologous Stem Cell Transplant in the Front-line Setting.. This study will find the max...\n",
      "[DEBUG] Encoding trial text for NCT04309084...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT04309084: 0.3947\n",
      "\n",
      "--- Processing NCT04489420 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT04489420 (first 300 chars):\n",
      "Natural Killer Cell (CYNK-001) IV Infusion or IT Administration in Adults With Recurrent GBM. A Phase I Study of Human Placental Hematopoietic Stem Cell Derived Natural Killer Cells (CYNK-001) in Adults With Recurrent Glioblastoma Multiforme (GBM). This study will find the maximum safe dose (MSD) or...\n",
      "[DEBUG] Encoding trial text for NCT04489420...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT04489420: 0.3677\n",
      "\n",
      "--- Processing NCT02460081 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT02460081 (first 300 chars):\n",
      "Safety, Hemodynamic Effects and Efficacy of Intramuscular PDA-002 in Subjects Who Have Diabetic Foot Ulcer With Peripheral Arterial Disease. A Phase 2, Multi-center, Randomized, Double-blind, Placebo-controlled, Dose Range Finding Study to Evaluate the Safety, Hemodynamic Effects and Efficacy of Int...\n",
      "[DEBUG] Encoding trial text for NCT02460081...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT02460081: 0.3677\n",
      "\n",
      "--- Processing NCT01769755 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01769755 (first 300 chars):\n",
      "A Randomized, Double-Blind, Placebo-Controlled Dose-Escalation Study to Determine the Safety and Efficacy of Intravenous Infusion of Human Placenta-Derived Cells (PDA001) for the Treatment of Crohn's Disease. A Randomized, Double-Blind, Placebo-Controlled Dose Escalation Study to Determine the Safet...\n",
      "[DEBUG] Encoding trial text for NCT01769755...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01769755: 0.3507\n",
      "\n",
      "--- Processing NCT02955550 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT02955550 (first 300 chars):\n",
      "A Safety Study of Human Cord Blood Derived, Culture-expanded, Natural Killer Cell (PNK-007) Infusion With or Without Subcutaneous Recombinant Human Interleukin-2 (rhIL-2) Following Autologous Stem Cell Transplant for Multiple Myeloma (MM). A Phase 1, Multicenter, Open-label, Safety Study of Human Co...\n",
      "[DEBUG] Encoding trial text for NCT02955550...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT02955550: 0.3227\n",
      "\n",
      "--- Processing NCT02552277 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT02552277 (first 300 chars):\n",
      "A Efficacy and Safety Study of Intramuscular Injection of Human Placenta-Derived Cells (PDA-002) in Subjects With Diabetic Peripheral Neuropathy. A Phase 2, Randomized, Double Blind, Placebo Controlled, Dose Range Finding Study to Access the Efficacy and Safety of Intramuscular Injection of Human Pl...\n",
      "[DEBUG] Encoding trial text for NCT02552277...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT02552277: 0.4803\n",
      "\n",
      "--- Processing NCT05218408 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT05218408 (first 300 chars):\n",
      "CYNK-001 IV and IC in Combination With IL2 in Surgical Eligible Recurrent GBM With IDH-1 Wild Type. A Phase I/IIa Open Label Multicenter, Non-Randomized, Trial to Assess the Safety and Efficacy of CYNK-001in Combination With Recombinant Human Interleukin-2 in Adults With Recurrent Resection Eligible...\n",
      "[DEBUG] Encoding trial text for NCT05218408...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT05218408: 0.2313\n",
      "\n",
      "--- Processing NCT01261403 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01261403 (first 300 chars):\n",
      "Study of Human Placenta-derived Cells (PDA001) to Evaluate the Safety and Effectiveness for Patients With Active Rheumatoid Arthritis. A Phase 2, Randomized, Double- Blind, Placebo-controlled, Multi-center Study to Evaluate the Safety and Efficacy of Intravenous Infusion of Human Placenta-Derived Ce...\n",
      "[DEBUG] Encoding trial text for NCT01261403...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01261403: 0.4170\n",
      "\n",
      "--- Processing NCT01310114 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT01310114 (first 300 chars):\n",
      "Study of Human Placenta-derived Cells (PDA001) to Evaluate the Safety and Effectiveness for Patients With Ischemic Stroke. A Phase 2A, Prospective, Multi-Center, Randomized, Double-Blind, Placebo-Controlled, Dose-Escalation Study to Evaluate the Safety of Intravenous Infusion of Human Placenta-Deriv...\n",
      "[DEBUG] Encoding trial text for NCT01310114...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT01310114: 0.4309\n",
      "\n",
      "--- Processing NCT02781467 ---\n",
      "\n",
      "[DEBUG] Aggregated Trial Text for NCT02781467 (first 300 chars):\n",
      "A Safety Study of Human Cord Blood Derived, Culture Expanded Natural Killer Cell (PNK-007) Infusion With Subcutaneous Recombinant Human IL-2 (rhIL-2) in Adults With Relapsed and/or Refractory Acute Myeloid Leukemia (AML). A Phase 1, Multicenter, Open-Label, Dose Escalating Safety Study of Human Cord...\n",
      "[DEBUG] Encoding trial text for NCT02781467...\n",
      "[DEBUG] Calculated Cosine Similarity Score for NCT02781467: 0.3116\n",
      "\n",
      "=== RANKED TRIALS ===\n",
      "  - NCT ID: NCT01859117, Score: 0.4816\n",
      "  - NCT ID: NCT02552277, Score: 0.4803\n",
      "  - NCT ID: NCT01310114, Score: 0.4309\n",
      "  - NCT ID: NCT04310592, Score: 0.4298\n",
      "  - NCT ID: NCT01261403, Score: 0.4170\n",
      "  - NCT ID: NCT04309084, Score: 0.3947\n",
      "  - NCT ID: NCT02264288, Score: 0.3945\n",
      "  - NCT ID: NCT01155362, Score: 0.3728\n",
      "  - NCT ID: NCT01440192, Score: 0.3715\n",
      "  - NCT ID: NCT02460081, Score: 0.3677\n",
      "  - NCT ID: NCT04489420, Score: 0.3677\n",
      "  - NCT ID: NCT04365101, Score: 0.3675\n",
      "  - NCT ID: NCT01769755, Score: 0.3507\n",
      "  - NCT ID: NCT02955550, Score: 0.3227\n",
      "  - NCT ID: NCT02781467, Score: 0.3116\n",
      "  - NCT ID: NCT05207722, Score: 0.2991\n",
      "  - NCT ID: NCT05218408, Score: 0.2313\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "\n",
    "# Import duckdb and SentenceTransformer\n",
    "import duckdb\n",
    "from sentence_transformers import SentenceTransformer, util # Import util for cosine similarity\n",
    "\n",
    "# --- Configuration ---\n",
    "DB_FILE = \"aact.duckdb\" # Make sure this file exists and contains the necessary tables\n",
    "\n",
    "# ======================\n",
    "# OPS CREDENTIALS\n",
    "# ======================\n",
    "CONSUMER_KEY = \"NVQKCR82CwTZzGPaO6ogoq6WVlbS0HVy1SnytQ1gIqewF6cl\"\n",
    "CONSUMER_SECRET = \"awuDXBZlb7Amy9dlRibwYzkAtCGCNHwnq4SY4NBXDCVw98K5FpFHHqXA746klglr\"\n",
    "\n",
    "# ======================\n",
    "# LENS.ORG FETCH\n",
    "# ======================\n",
    "def fetch_lens_patent_data(lens_id: str) -> dict:\n",
    "    \"\"\"Fetches initial patent data from Lens.org\"\"\"\n",
    "    url = f\"https://www.lens.org/lens/export/patent?q=lens_id%3A%22{lens_id}%22&st=true\"\n",
    "    try:\n",
    "        response = requests.post(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if response.text and len(response.text.splitlines()) > 1:\n",
    "            df = pd.read_csv(io.StringIO(response.text))\n",
    "            if not df.empty:\n",
    "                row = df.iloc[0].to_dict()\n",
    "                \n",
    "                # Extract publication number and clean it\n",
    "                pub_number = str(row.get(\"Publication Number\", \"\")).strip()\n",
    "                if not pub_number:\n",
    "                    # Try Display Key as fallback\n",
    "                    pub_number = str(row.get(\"Display Key\", \"\")).replace(\" \", \"\")\n",
    "\n",
    "                return {\n",
    "                    \"lens_id\": row.get(\"Lens ID\", lens_id),\n",
    "                    \"publication_number\": pub_number,\n",
    "                    \"title\": str(row.get(\"Title\", \"\")),\n",
    "                    \"abstract\": str(row.get(\"Abstract\", \"\")),\n",
    "                    \"claims\": [], # Will be populated from EPO\n",
    "                    \"owners\": str(row.get(\"Owners\", \"\")),\n",
    "                    \"applicants\": str(row.get(\"Applicants\", \"\")),\n",
    "                    \"source\": \"Lens.org\"\n",
    "                }\n",
    "        return {\"lens_id\": lens_id, \"error\": \"Patent not found\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"lens_id\": lens_id, \"error\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "# ======================\n",
    "# EPO OPS FETCH\n",
    "# ======================\n",
    "def get_access_token():\n",
    "    url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "    response = requests.post(url, data=data, auth=HTTPBasicAuth(CONSUMER_KEY, CONSUMER_SECRET))\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "def fetch_epo_patent_data(pub_number: str) -> dict:\n",
    "    \"\"\"Fetch title, abstract, and claims from EPO OPS\"\"\"\n",
    "    try:\n",
    "        token = get_access_token()\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\", \"Accept\": \"application/xml\"}\n",
    "\n",
    "        # Clean and parse publication number\n",
    "        pub_number = pub_number.replace(\"/\", \"\").replace(\" \", \"\")\n",
    "        match = re.match(r\"([A-Z]+)(\\d+)([A-Z]\\d*)\", pub_number)\n",
    "        if not match:\n",
    "            return {\"error\": f\"Invalid publication number format: {pub_number}\"}\n",
    "            \n",
    "        country, number, kind = match.groups()\n",
    "        docdb_number = f\"{country}.{number}.{kind}\"\n",
    "        print(f\"üîç Using DOCDB number: {docdb_number}\")\n",
    "\n",
    "        # Fetch claims\n",
    "        url_claims = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_number}/claims\"\n",
    "        response = requests.get(url_claims, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        claims = parse_claims(response.text)\n",
    "        print(f\"üìÑ Found {len(claims)} claims\")\n",
    "\n",
    "        # Fetch biblio data\n",
    "        url_biblio = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_number}/biblio\"\n",
    "        response = requests.get(url_biblio, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        title, abstract = parse_biblio(response.text)\n",
    "        print(\"üìö Retrieved bibliographic data\")\n",
    "\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"claims\": claims,\n",
    "            \"source\": \"EPO OPS\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå EPO fetch error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ======================\n",
    "# PARSERS\n",
    "# ======================\n",
    "def parse_claims(xml_data: str) -> list:\n",
    "    \"\"\"Parse claims from EPO XML response\"\"\"\n",
    "    ns = {\"ftxt\": \"http://www.epo.org/fulltext\"}\n",
    "    try:\n",
    "        root = ET.fromstring(xml_data)\n",
    "        claims = []\n",
    "        \n",
    "        # Try both direct claim-text and nested claim structures\n",
    "        for claim in root.findall(\".//ftxt:claim\", ns):\n",
    "            texts = claim.findall(\".//ftxt:claim-text\", ns)\n",
    "            claim_text = \" \".join(t.text.strip() for t in texts if t.text)\n",
    "            if claim_text and not claim_text.upper().startswith(\"WHAT IS CLAIMED IS\"):\n",
    "                claims.append(claim_text)\n",
    "                \n",
    "        if not claims:\n",
    "            # Fallback: try to split by claim numbers\n",
    "            text_elements = root.findall(\".//ftxt:claim-text\", ns)\n",
    "            full_text = \" \".join(t.text.strip() for t in text_elements if t.text)\n",
    "            claims = [c.strip() for c in re.split(r\"\\s*\\d+\\.\\s+\", full_text) if c.strip()]\n",
    "            \n",
    "        return claims\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"‚ùå XML Parse error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def parse_biblio(xml_data: str) -> tuple:\n",
    "    \"\"\"Parse title and abstract from EPO XML response\"\"\"\n",
    "    ns = {\"ep\": \"http://www.epo.org/exchange\"}\n",
    "    try:\n",
    "        root = ET.fromstring(xml_data)\n",
    "        \n",
    "        # Try to find English title first, then any title\n",
    "        titles = root.findall(\".//ep:invention-title\", ns)\n",
    "        title = \"\"\n",
    "        for t in titles:\n",
    "            if t.get(\"lang\") == \"en\" and t.text:\n",
    "                title = t.text.strip()\n",
    "                break\n",
    "        if not title and titles:\n",
    "            title = titles[0].text.strip() if titles[0].text else \"\"\n",
    "\n",
    "        # Get abstract\n",
    "        abstract = \"\"\n",
    "        abstract_elem = root.find(\".//ep:abstract/ep:p\", ns)\n",
    "        if abstract_elem is not None and abstract_elem.text:\n",
    "            abstract = abstract_elem.text.strip()\n",
    "\n",
    "        return title, abstract\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"‚ùå XML Parse error: {str(e)}\")\n",
    "        return \"\", \"\"\n",
    "# ======================\n",
    "# INTEGRATED FETCHER\n",
    "# ======================\n",
    "def get_patent_metadata(lens_id: str) -> dict:\n",
    "    \"\"\"Main function to fetch and combine patent data\"\"\"\n",
    "    print(f\"üîç Fetching patent data for Lens ID: {lens_id}\")\n",
    "    \n",
    "    # First get data from Lens.org\n",
    "    lens_data = fetch_lens_patent_data(lens_id)\n",
    "    if \"error\" in lens_data:\n",
    "        return lens_data\n",
    "\n",
    "    # Try to enrich with EPO data if we have a publication number\n",
    "    pub_number = lens_data.get(\"publication_number\", \"\").strip()\n",
    "    if pub_number:\n",
    "        print(f\"üìë Found publication number: {pub_number}\")\n",
    "        epo_data = fetch_epo_patent_data(pub_number)\n",
    "        \n",
    "        if \"error\" not in epo_data:\n",
    "            # Combine data, preferring EPO where available\n",
    "            lens_data.update({\n",
    "                \"title\": epo_data.get(\"title\") or lens_data.get(\"title\", \"\"),\n",
    "                \"abstract\": epo_data.get(\"abstract\") or lens_data.get(\"abstract\", \"\"),\n",
    "                \"claims\": epo_data.get(\"claims\", []),\n",
    "                \"source\": \"EPO OPS + Lens.org\"\n",
    "            })\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è EPO data fetch failed, using Lens.org data only\")\n",
    "            lens_data[\"source\"] = \"Lens.org only\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No publication number found, using Lens.org data only\")\n",
    "        lens_data[\"source\"] = \"Lens.org only\"\n",
    "\n",
    "    return lens_data\n",
    "\n",
    "# ======================\n",
    "# MATCHING + RANKING\n",
    "# ======================\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    if not isinstance(name, str): return \"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[,.\\s]*(inc|incorporated|ltd|llc|corp|gmbh|ag|plc|sa)\\b.*$', '', name)\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    return name.strip()\n",
    "\n",
    "def find_sponsor_matches(patent_data: dict) -> list:\n",
    "    if \"error\" in patent_data: return []\n",
    "    all_names_raw = []\n",
    "    owners_str = str(patent_data.get(\"owners\", \"\"))\n",
    "    applicants_str = str(patent_data.get(\"applicants\", \"\"))\n",
    "    if owners_str: all_names_raw.extend(owners_str.split(';'))\n",
    "    if applicants_str: all_names_raw.extend(applicants_str.split(';'))\n",
    "\n",
    "    normalized_sponsors = { normalize_name(name) for name in all_names_raw if normalize_name(name) and 'nan' not in normalize_name(name) }\n",
    "    print(f\"[DEBUG] Normalized sponsor names for search: {normalized_sponsors}\")\n",
    "\n",
    "    if not normalized_sponsors: return []\n",
    "    matches = []\n",
    "    try:\n",
    "        con = duckdb.connect(database=DB_FILE, read_only=True)\n",
    "        # Ensure 'norm_name' column exists in 'sponsors' table or adjust query\n",
    "        where_clauses = \" OR \".join([f\"lower(name) LIKE '%{s}%'\" for s in normalized_sponsors])\n",
    "        sql_query = f\"\"\"SELECT s.nct_id, s.official_title, s.start_date, sp.name AS sponsor_name FROM studies AS s JOIN sponsors AS sp ON s.nct_id = sp.nct_id WHERE ({where_clauses});\"\"\"\n",
    "        print(f\"[DEBUG] Executing Sponsor Match SQL Query:\\n{sql_query}\")\n",
    "        results = con.execute(sql_query).fetchall()\n",
    "        print(f\"[DEBUG] Sponsor match query returned {len(results)} rows.\")\n",
    "        for row in results:\n",
    "            matches.append({ \"nct_id\": row[0], \"title\": row[1], \"start_date\": row[2], \"sponsor\": row[3] })\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] An error occurred during database query: {e}\")\n",
    "    finally:\n",
    "        if 'con' in locals(): con.close()\n",
    "    return matches\n",
    "\n",
    "def get_patent_full_text(patent_info: dict) -> str:\n",
    "    # Ensure claims is a string or list of strings before joining\n",
    "    claims_text = \"\"\n",
    "    if isinstance(patent_info.get(\"claims\"), list):\n",
    "        claims_text = \". \".join(patent_info.get(\"claims\"))\n",
    "    elif isinstance(patent_info.get(\"claims\"), str):\n",
    "        claims_text = patent_info.get(\"claims\")\n",
    "\n",
    "    full_text = \". \".join(filter(None, [ # Use filter(None) to remove empty strings\n",
    "        patent_info.get(\"title\", \"\"),\n",
    "        patent_info.get(\"abstract\", \"\"),\n",
    "        claims_text\n",
    "    ]))\n",
    "    print(\"\\n[DEBUG] Aggregated Patent Text (first 300 chars):\")\n",
    "    print(full_text[:300] + \"...\")\n",
    "    return full_text\n",
    "\n",
    "def get_trial_full_text(nct_id: str, con) -> str:\n",
    "    text_parts = []\n",
    "\n",
    "    studies_res = con.execute(f\"SELECT brief_title, official_title FROM studies WHERE nct_id = '{nct_id}'\").fetchone()\n",
    "    if studies_res: text_parts.extend(studies_res)\n",
    "\n",
    "    summary_res = con.execute(f\"SELECT description FROM brief_summaries WHERE nct_id = '{nct_id}'\").fetchone()\n",
    "    if summary_res: text_parts.extend(summary_res)\n",
    "\n",
    "    desc_res = con.execute(f\"SELECT description FROM detailed_descriptions WHERE nct_id = '{nct_id}'\").fetchone()\n",
    "    if desc_res: text_parts.extend(desc_res)\n",
    "\n",
    "    int_res = con.execute(f\"SELECT name, description FROM interventions WHERE nct_id = '{nct_id}'\").fetchall()\n",
    "    for row in int_res: text_parts.extend(row)\n",
    "\n",
    "    cond_res = con.execute(f\"SELECT mesh_term FROM browse_conditions WHERE nct_id = '{nct_id}'\").fetchall()\n",
    "    for row in cond_res: text_parts.extend(row)\n",
    "\n",
    "    full_text = \". \".join([str(part) for part in text_parts if part])\n",
    "    print(f\"\\n[DEBUG] Aggregated Trial Text for {nct_id} (first 300 chars):\")\n",
    "    print(full_text[:300] + \"...\")\n",
    "    return full_text\n",
    "\n",
    "def rank_by_semantic_similarity(sponsor_matches: list, patent_info: dict) -> list:\n",
    "    print(\"\\n[DEBUG] Initializing SentenceTransformer model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    patent_text = get_patent_full_text(patent_info)\n",
    "    print(\"[DEBUG] Encoding patent text into a vector...\")\n",
    "    patent_embedding = model.encode(patent_text, convert_to_tensor=True)\n",
    "\n",
    "    ranked_trials = []\n",
    "    con = duckdb.connect(database=DB_FILE, read_only=True)\n",
    "\n",
    "    print(\"\\n[DEBUG] Starting to process and score each candidate trial...\")\n",
    "    for trial in sponsor_matches:\n",
    "        nct_id = trial['nct_id']\n",
    "        print(f\"\\n--- Processing {nct_id} ---\")\n",
    "        trial_text = get_trial_full_text(trial['nct_id'], con)\n",
    "\n",
    "        if not trial_text:\n",
    "            trial['semantic_score'] = 0\n",
    "            ranked_trials.append(trial)\n",
    "            print(f\"[DEBUG] No text found for {nct_id}. Score set to 0.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[DEBUG] Encoding trial text for {nct_id}...\")\n",
    "        trial_embedding = model.encode(trial_text, convert_to_tensor=True)\n",
    "\n",
    "        cosine_score = util.pytorch_cos_sim(patent_embedding, trial_embedding).item()\n",
    "        print(f\"[DEBUG] Calculated Cosine Similarity Score for {nct_id}: {cosine_score:.4f}\")\n",
    "\n",
    "        trial['semantic_score'] = cosine_score\n",
    "        ranked_trials.append(trial)\n",
    "\n",
    "    con.close()\n",
    "\n",
    "    return sorted(ranked_trials, key=lambda x: x['semantic_score'], reverse=True)\n",
    "\n",
    "# ======================\n",
    "# MAIN\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    lens_id = \"023-587-103-542-962\"  # replace with actual Lens ID\n",
    "    patent_info = get_patent_metadata(lens_id)\n",
    "\n",
    "    print(\"\\n=== PATENT METADATA ===\")\n",
    "    print(\"üìë Source:\", patent_info.get(\"source\", \"Unknown\"))\n",
    "    print(\"üîë Publication:\", patent_info.get(\"publication_number\"))\n",
    "    print(\"üìù Title:\", patent_info.get(\"title\"))\n",
    "    print(\"üìñ Abstract:\", patent_info.get(\"abstract\", \"\")[:200], \"...\")\n",
    "    \n",
    "    # Add detailed claims preview\n",
    "    print(\"\\n=== CLAIMS PREVIEW ===\")\n",
    "    claims = patent_info.get(\"claims\", [])\n",
    "    if isinstance(claims, list) and claims:\n",
    "        for i, claim in enumerate(claims, 1):\n",
    "            # Show first 50 characters of each claim\n",
    "            preview = claim[:50].replace('\\n', ' ').strip()\n",
    "            print(f\"Claim {i}: {preview}...\")\n",
    "    else:\n",
    "        print(\"‚ùå No claims found in the patent data\")\n",
    "\n",
    "    if \"error\" not in patent_info:\n",
    "        try:\n",
    "            initial_matches = find_sponsor_matches(patent_info)\n",
    "            ranked_trials = rank_by_semantic_similarity(initial_matches, patent_info)\n",
    "            print(\"\\n=== RANKED TRIALS ===\")\n",
    "            for trial in ranked_trials:\n",
    "                print(f\"  - NCT ID: {trial['nct_id']}, Score: {trial['semantic_score']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå An error occurred during matching/ranking: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {patent_info.get('error', 'Unknown error')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
