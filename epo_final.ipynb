{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd08d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nüöÄ EXECUTING COMPREHENSIVE SEARCH...\n",
      "üöÄ COMPREHENSIVE EPO PATENT DATA EXTRACTION\n",
      "‚ú® Features: Titles, Inventors, Applicants, Abstracts, Claims, INPADOC Family\n",
      "üîó Format: || separators for all multi-value fields\n",
      "Query: Alpha-2-macroglobulin\n",
      "Max results: 25\n",
      "================================================================================\n",
      "üìù Step 1: Basic patent search...\n",
      "üîç Found 25 patents. Extracting basic data...\n",
      "  Processed 5/25 patents...\n",
      "  Processed 10/25 patents...\n",
      "  Processed 15/25 patents...\n",
      "  Processed 20/25 patents...\n",
      "  Processed 25/25 patents...\n",
      "‚úÖ Extracted basic data for 25 patents\n",
      "\\nüìä Step 2: Getting comprehensive data for 25 patents...\n",
      "  Processing 1/25: US2025270292A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 2/25: US2025205319A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 3/25: NZ740279A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 37 members\n",
      "    ‚úÖ Completed 3/25 patents\n",
      "  Processing 4/25: NZ746485A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 31 members\n",
      "  Processing 5/25: US2025032683A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "  Processing 6/25: US2025025610A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "    ‚úÖ Completed 6/25 patents\n",
      "  Processing 7/25: US2024424056A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 7 members\n",
      "  Processing 8/25: WO2024238028A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "  Processing 9/25: WO2024238027A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "    ‚úÖ Completed 9/25 patents\n",
      "  Processing 10/25: US2024374745A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "  Processing 11/25: WO2024211493A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 2 members\n",
      "  Processing 12/25: TW202426480A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 3 members\n",
      "    ‚úÖ Completed 12/25 patents\n",
      "  Processing 13/25: CN118613501A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "  Processing 14/25: TW202421658A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 3 members\n",
      "  Processing 15/25: WO2024261212A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 1 members\n",
      "    ‚úÖ Completed 15/25 patents\n",
      "  Processing 16/25: US2024197969A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "  Processing 17/25: US2024100229A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 14 members\n",
      "  Processing 18/25: KR20240009366A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 4 members\n",
      "    ‚úÖ Completed 18/25 patents\n",
      "  Processing 19/25: US2024033332A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 5 members\n",
      "  Processing 20/25: CA3226847A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 7 members\n",
      "  Processing 21/25: WO2024014834A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 4 members\n",
      "    ‚úÖ Completed 21/25 patents\n",
      "  Processing 22/25: CN117164665A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 1 members\n",
      "  Processing 23/25: WO2024084398A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 3 members\n",
      "  Processing 24/25: WO2024084400A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 3 members\n",
      "    ‚úÖ Completed 24/25 patents\n",
      "  Processing 25/25: CN116718776A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 1 members\n",
      "\\nüíæ Step 3: Creating comprehensive CSV export...\n",
      "‚úÖ Successfully exported 25 patents to EPO_Patent_Dataset_Alpha-2-macroglobulin.csv\n",
      "Patents with INPADOC family data: 25\n",
      "\\nüìä STATISTICS:\n",
      "Average abstract length: 555 characters\n",
      "Average family size: 10.2 members\n",
      "\\nüéØ SAMPLE || SEPARATOR FORMAT:\n",
      "Patent: US2025270292A1\n",
      "Inventors: HANNA LEWIS‚ÄÇ[US] || LAUGHLIN JOHN DAVID‚ÄÇ[US] || BROWNING SHAWN ROBERT‚ÄÇ[US] || HANNA, Lewis, || LAUGH...\n",
      "Jurisdictions: US || AU || AU || CA || EP || EP || EP || JP || JP || JP || JP || US || US || US || US || US || US |...\n",
      "\\nüéâ SUCCESS! Comprehensive patent dataset created!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# FINAL COMPLETE EPO PATENT SEARCH SYSTEM\n",
    "# Complete solution with all functions integrated\n",
    "# ==============================================\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "# from collections import Counter\n",
    "\n",
    "class EPOPatentSearchSystem:\n",
    "    \"\"\"\n",
    "    Complete EPO Patent Search System with INPADOC family data, abstracts, and claims.\n",
    "    Features:\n",
    "    - Comprehensive patent search\n",
    "    - Title, inventors, applicants extraction\n",
    "    - Abstract and claims retrieval\n",
    "    - INPADOC extended family data\n",
    "    - || separator formatting\n",
    "    - Jurisdiction mapping and family member lists\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, consumer_key: str, consumer_secret: str):\n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = None\n",
    "        self.namespaces = {\n",
    "            'ops': 'http://ops.epo.org',\n",
    "            'ep': 'http://www.epo.org/exchange'\n",
    "        }\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get EPO OPS access token.\"\"\"\n",
    "        url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        data = {\"grant_type\": \"client_credentials\"}\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                url, \n",
    "                data=data, \n",
    "                auth=HTTPBasicAuth(self.consumer_key, self.consumer_secret)\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            self.access_token = response.json()[\"access_token\"]\n",
    "            return self.access_token\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Token error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _ensure_token(self):\n",
    "        \"\"\"Ensure we have a valid access token.\"\"\"\n",
    "        if not self.access_token:\n",
    "            return self.get_access_token()\n",
    "        return self.access_token\n",
    "    \n",
    "    def _convert_to_docdb_format(self, publication_number: str):\n",
    "        \"\"\"Convert publication number to DOCDB format.\"\"\"\n",
    "        if publication_number.startswith(('US', 'EP', 'WO', 'JP', 'CN')) and len(publication_number) > 2:\n",
    "            c = publication_number[:2]\n",
    "            rest = publication_number[2:]\n",
    "            for i, char in enumerate(rest):\n",
    "                if char.isalpha():\n",
    "                    n = rest[:i]\n",
    "                    k = rest[i:]\n",
    "                    break\n",
    "            else:\n",
    "                n = rest\n",
    "                k = \"\"\n",
    "            return f\"{c}.{n}.{k}\" if k else f\"{c}.{n}\"\n",
    "        return publication_number\n",
    "    \n",
    "    def search_patents(self, search_query: str, max_results: int = 25):\n",
    "        \"\"\"\n",
    "        Search for patents using EPO OPS API.\n",
    "        \n",
    "        Args:\n",
    "            search_query: EPO search query string\n",
    "            max_results: Maximum number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of patent dictionaries with basic information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return []\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        url = f\"https://ops.epo.org/3.2/rest-services/published-data/search\"\n",
    "        \n",
    "        params = {\n",
    "            \"q\": search_query,\n",
    "            \"Range\": f\"1-{max_results}\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            if response.ok:\n",
    "                root = ET.fromstring(response.content)\n",
    "                \n",
    "                patent_refs = root.findall(\".//ops:publication-reference\", self.namespaces)\n",
    "                patents_data = []\n",
    "                \n",
    "                print(f\"üîç Found {len(patent_refs)} patents. Extracting basic data...\")\n",
    "                \n",
    "                for i, patent_ref in enumerate(patent_refs, 1):\n",
    "                    doc_id = patent_ref.find(\".//ep:document-id[@document-id-type='docdb']\", self.namespaces)\n",
    "                    if doc_id is not None:\n",
    "                        country = doc_id.find(\"ep:country\", self.namespaces)\n",
    "                        number = doc_id.find(\"ep:doc-number\", self.namespaces)\n",
    "                        kind = doc_id.find(\"ep:kind\", self.namespaces)\n",
    "                        date = doc_id.find(\"ep:date\", self.namespaces)\n",
    "                        \n",
    "                        if all(x is not None and x.text for x in [country, number, kind]):\n",
    "                            publication_num = f\"{country.text}{number.text}{kind.text}\"\n",
    "                            pub_date = date.text if date is not None and date.text else \"\"\n",
    "                            \n",
    "                            # Get title if available\n",
    "                            title_elem = patent_ref.find(\".//ep:invention-title[@lang='en']\", self.namespaces)\n",
    "                            title = title_elem.text if title_elem is not None and title_elem.text else \"\"\n",
    "                            \n",
    "                            patent_data = {\n",
    "                                'publication_number': publication_num,\n",
    "                                'country': country.text,\n",
    "                                'doc_number': number.text,\n",
    "                                'kind': kind.text,\n",
    "                                'publication_date': pub_date,\n",
    "                                'title': title,\n",
    "                                'search_index': i\n",
    "                            }\n",
    "                            \n",
    "                            patents_data.append(patent_data)\n",
    "                            \n",
    "                            if i % 5 == 0:\n",
    "                                print(f\"  Processed {i}/{len(patent_refs)} patents...\")\n",
    "                \n",
    "                print(f\"‚úÖ Extracted basic data for {len(patents_data)} patents\")\n",
    "                return patents_data\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Search failed: {response.status_code}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_patent_details(self, publication_number: str, retries: int = 3):\n",
    "        \"\"\"\n",
    "        Get detailed patent information including title, inventors, applicants, abstract, and claims.\n",
    "        \n",
    "        Args:\n",
    "            publication_number: Patent publication number\n",
    "            retries: Number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with detailed patent information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return {}\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        docdb_format = self._convert_to_docdb_format(publication_number)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        # Get bibliographic data (title, inventors, applicants)\n",
    "        biblio_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/biblio\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(biblio_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract title\n",
    "                    title_elem = root.find(\".//ep:invention-title[@lang='en']\", self.namespaces)\n",
    "                    result['title'] = title_elem.text if title_elem is not None else \"\"\n",
    "                    \n",
    "                    # Extract inventors\n",
    "                    inventors = []\n",
    "                    inventor_elems = root.findall(\".//ep:inventor\", self.namespaces)\n",
    "                    for inv in inventor_elems:\n",
    "                        name_elem = inv.find(\".//ep:name\", self.namespaces)\n",
    "                        if name_elem is not None and name_elem.text:\n",
    "                            inventors.append(name_elem.text.strip())\n",
    "                    \n",
    "                    # Extract applicants\n",
    "                    applicants = []\n",
    "                    applicant_elems = root.findall(\".//ep:applicant\", self.namespaces)\n",
    "                    for app in applicant_elems:\n",
    "                        name_elem = app.find(\".//ep:name\", self.namespaces)\n",
    "                        if name_elem is not None and name_elem.text:\n",
    "                            applicants.append(name_elem.text.strip())\n",
    "                    \n",
    "                    result.update({\n",
    "                        'inventors': ' || '.join(inventors) if inventors else '',\n",
    "                        'applicants': ' || '.join(applicants) if applicants else '',\n",
    "                        'inventors_count': len(inventors),\n",
    "                        'applicants_count': len(applicants)\n",
    "                    })\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Biblio failed for {publication_number}: {response.status_code}\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Biblio error for {publication_number} (attempt {attempt + 1}): {e}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # Get abstract\n",
    "        abstract_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/abstract\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(abstract_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract abstract\n",
    "                    abstract_elem = root.find(\".//ep:abstract[@lang='en']\", self.namespaces)\n",
    "                    if abstract_elem is not None:\n",
    "                        # Get all text from abstract, including from paragraphs\n",
    "                        abstract_texts = []\n",
    "                        for p in abstract_elem.findall(\".//ep:p\", self.namespaces):\n",
    "                            if p.text:\n",
    "                                abstract_texts.append(p.text.strip())\n",
    "                        \n",
    "                        if abstract_texts:\n",
    "                            result['abstract'] = ' '.join(abstract_texts)\n",
    "                        elif abstract_elem.text:\n",
    "                            result['abstract'] = abstract_elem.text.strip()\n",
    "                        else:\n",
    "                            result['abstract'] = \"\"\n",
    "                    else:\n",
    "                        result['abstract'] = \"\"\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    result['abstract'] = \"\"\n",
    "                    if response.status_code != 404:  # 404 is normal for missing abstracts\n",
    "                        print(f\"‚ö†Ô∏è Abstract failed for {publication_number}: {response.status_code}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                result['abstract'] = \"\"\n",
    "                break\n",
    "        \n",
    "        # Get claims\n",
    "        claims_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/claims\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(claims_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract claims\n",
    "                    claims_texts = []\n",
    "                    claim_elems = root.findall(\".//ep:claim[@lang='en']\", self.namespaces)\n",
    "                    for claim in claim_elems:\n",
    "                        claim_num = claim.get('num', '')\n",
    "                        claim_text = \"\"\n",
    "                        \n",
    "                        # Get text from paragraphs within claim\n",
    "                        for p in claim.findall(\".//ep:claim-text\", self.namespaces):\n",
    "                            if p.text:\n",
    "                                claim_text += p.text.strip() + \" \"\n",
    "                        \n",
    "                        if claim_text.strip():\n",
    "                            claims_texts.append(f\"Claim {claim_num}: {claim_text.strip()}\")\n",
    "                    \n",
    "                    if claims_texts:\n",
    "                        result['claims'] = ' || '.join(claims_texts[:5])  # Limit to first 5 claims\n",
    "                    else:\n",
    "                        result['claims'] = \"\"\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    result['claims'] = \"\"\n",
    "                    if response.status_code != 404:  # 404 is normal for missing claims\n",
    "                        print(f\"‚ö†Ô∏è Claims failed for {publication_number}: {response.status_code}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                result['claims'] = \"\"\n",
    "                break\n",
    "        \n",
    "        # Set defaults for missing data\n",
    "        default_fields = ['title', 'inventors', 'applicants', 'abstract', 'claims']\n",
    "        for field in default_fields:\n",
    "            if field not in result:\n",
    "                result[field] = \"\"\n",
    "        \n",
    "        if 'inventors_count' not in result:\n",
    "            result['inventors_count'] = 0\n",
    "        if 'applicants_count' not in result:\n",
    "            result['applicants_count'] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_inpadoc_family_data(self, publication_number: str, retries: int = 3):\n",
    "        \"\"\"\n",
    "        Get INPADOC extended family data with enhanced formatting.\n",
    "        \n",
    "        Args:\n",
    "            publication_number: Patent publication number\n",
    "            retries: Number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with INPADOC family information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return {}\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        docdb_format = self._convert_to_docdb_format(publication_number)\n",
    "        \n",
    "        url = f\"https://ops.epo.org/3.2/rest-services/family/publication/docdb/{docdb_format}\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Get family information\n",
    "                    family_elem = root.find(\".//ops:patent-family\", self.namespaces)\n",
    "                    total_count = family_elem.get('total-result-count', '0') if family_elem is not None else '0'\n",
    "                    \n",
    "                    # Get all family members\n",
    "                    family_members = root.findall(\".//ops:family-member\", self.namespaces)\n",
    "                    \n",
    "                    # Collect jurisdictions and members\n",
    "                    jurisdiction_list = []\n",
    "                    all_family_members = []\n",
    "                    \n",
    "                    for member in family_members:\n",
    "                        # publication-reference is in the ep namespace\n",
    "                        pub_ref = member.find(\".//ep:publication-reference\", self.namespaces)\n",
    "                        if pub_ref is not None:\n",
    "                            # document-id elements are also in ep namespace\n",
    "                            doc_id = pub_ref.find(\".//ep:document-id[@document-id-type='docdb']\", self.namespaces)\n",
    "                            if doc_id is not None:\n",
    "                                country = doc_id.find(\"ep:country\", self.namespaces)\n",
    "                                number = doc_id.find(\"ep:doc-number\", self.namespaces)\n",
    "                                kind = doc_id.find(\"ep:kind\", self.namespaces)\n",
    "                                date = doc_id.find(\"ep:date\", self.namespaces)\n",
    "                                \n",
    "                                if all(x is not None and x.text for x in [country, number, kind]):\n",
    "                                    country_code = country.text\n",
    "                                    pub_num = f\"{country_code}{number.text}{kind.text}\"\n",
    "                                    pub_date = date.text if date is not None and date.text else \"\"\n",
    "                                    \n",
    "                                    # Add to jurisdiction list for each occurrence\n",
    "                                    jurisdiction_list.append(country_code)\n",
    "                                    \n",
    "                                    all_family_members.append({\n",
    "                                        'publication': pub_num,\n",
    "                                        'country': country_code,\n",
    "                                        'date': pub_date\n",
    "                                    })\n",
    "                    \n",
    "                    # Create jurisdiction string with || separator (showing each occurrence)\n",
    "                    jurisdiction_string = ' || '.join(jurisdiction_list)\n",
    "                    \n",
    "                    # Create family members string with || separator\n",
    "                    family_members_string = ' || '.join([member['publication'] for member in all_family_members])\n",
    "                    \n",
    "                    return {\n",
    "                        'inpadoc_family_size': len(all_family_members),\n",
    "                        'inpadoc_jurisdictions_count': len(set(jurisdiction_list)),\n",
    "                        'inpadoc_jurisdiction_list': jurisdiction_string,\n",
    "                        'inpadoc_family_members': family_members_string\n",
    "                    }\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Family failed for {publication_number}: {response.status_code}\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Family error for {publication_number} (attempt {attempt + 1}): {e}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def create_comprehensive_dataset(self, search_query: str, max_results: int = 25, output_filename: str = None):\n",
    "        \"\"\"\n",
    "        Create comprehensive patent dataset with all features.\n",
    "        \n",
    "        Args:\n",
    "            search_query: EPO search query string\n",
    "            max_results: Maximum number of patents to process\n",
    "            output_filename: Output CSV filename (auto-generated if None)\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame with comprehensive patent data\n",
    "        \"\"\"\n",
    "        if output_filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"comprehensive_patent_data_{timestamp}.csv\"\n",
    "        \n",
    "        print(f\"üöÄ COMPREHENSIVE EPO PATENT DATA EXTRACTION\")\n",
    "        print(f\"‚ú® Features: Titles, Inventors, Applicants, Abstracts, Claims, INPADOC Family\")\n",
    "        print(f\"üîó Format: || separators for all multi-value fields\")\n",
    "        print(f\"Query: {search_query}\")\n",
    "        print(f\"Max results: {max_results}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Step 1: Basic search\n",
    "        print(\"üìù Step 1: Basic patent search...\")\n",
    "        basic_patents = self.search_patents(search_query, max_results)\n",
    "        \n",
    "        if not basic_patents:\n",
    "            print(\"‚ùå No patents found in basic search\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Get comprehensive data for each patent\n",
    "        print(f\"\\\\nüìä Step 2: Getting comprehensive data for {len(basic_patents)} patents...\")\n",
    "        comprehensive_data = []\n",
    "        \n",
    "        for i, patent in enumerate(basic_patents, 1):\n",
    "            pub_num = patent['publication_number']\n",
    "            print(f\"  Processing {i}/{len(basic_patents)}: {pub_num}\")\n",
    "            \n",
    "            # Start with basic data\n",
    "            patent_data = patent.copy()\n",
    "            \n",
    "            # Get detailed data (title, inventors, applicants, abstract, claims)\n",
    "            detailed_data = self.get_patent_details(pub_num)\n",
    "            patent_data.update(detailed_data)\n",
    "            \n",
    "            # Get INPADOC family data\n",
    "            family_data = self.get_inpadoc_family_data(pub_num)\n",
    "            patent_data.update(family_data)\n",
    "            \n",
    "            # Show progress\n",
    "            abstract_status = \"‚úì\" if detailed_data.get('abstract', '') else \"‚úó\"\n",
    "            claims_status = \"‚úì\" if detailed_data.get('claims', '') else \"‚úó\"\n",
    "            family_size = family_data.get('inpadoc_family_size', 0)\n",
    "            \n",
    "            print(f\"    üìÑ Abstract: {abstract_status} | üìã Claims: {claims_status} | üë• Family: {family_size} members\")\n",
    "            \n",
    "            comprehensive_data.append(patent_data)\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.8)\n",
    "            \n",
    "            if i % 3 == 0:\n",
    "                print(f\"    ‚úÖ Completed {i}/{len(basic_patents)} patents\")\n",
    "        \n",
    "        # Step 3: Create DataFrame and export\n",
    "        print(f\"\\\\nüíæ Step 3: Creating comprehensive CSV export...\")\n",
    "        df = pd.DataFrame(comprehensive_data)\n",
    "        \n",
    "        # Define complete column structure\n",
    "        expected_columns = [\n",
    "            'publication_number', 'country', 'doc_number', 'kind', 'publication_date',\n",
    "            'title', 'abstract', 'claims',\n",
    "            'inventors', 'applicants', 'inventors_count', 'applicants_count',\n",
    "            'inpadoc_family_size', 'inpadoc_jurisdictions_count', \n",
    "            'inpadoc_jurisdiction_list', 'inpadoc_family_members', 'search_index'\n",
    "        ]\n",
    "        \n",
    "        for col in expected_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = ''\n",
    "        \n",
    "        # Reorder columns\n",
    "        df = df[expected_columns]\n",
    "        \n",
    "        # Export to CSV\n",
    "        try:\n",
    "            df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"‚úÖ Successfully exported {len(df)} patents to {output_filename}\")\n",
    "            \n",
    "            \n",
    "            # INPADOC family statistics\n",
    "            patents_with_family = len(df[df['inpadoc_family_size'] > 0])\n",
    "            print(f\"Patents with INPADOC family data: {patents_with_family}\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                avg_abstract_length = df[df['abstract'] != '']['abstract'].str.len().mean() if len(df[df['abstract'] != '']) > 0 else 0\n",
    "                avg_family_size = df['inpadoc_family_size'].mean()\n",
    "                \n",
    "                print(f\"\\\\nüìä STATISTICS:\")\n",
    "                print(f\"Average abstract length: {avg_abstract_length:.0f} characters\")\n",
    "                print(f\"Average family size: {avg_family_size:.1f} members\")\n",
    "                \n",
    "                # Show sample format\n",
    "                print(f\"\\\\nüéØ SAMPLE || SEPARATOR FORMAT:\")\n",
    "                if len(df) > 0:\n",
    "                    sample = df.iloc[0]\n",
    "                    print(f\"Patent: {sample['publication_number']}\")\n",
    "                    \n",
    "                    # Show sample data\n",
    "                    inventors_sample = str(sample['inventors'])[:100] + \"...\" if len(str(sample['inventors'])) > 100 else str(sample['inventors'])\n",
    "                    jurisdictions_sample = str(sample['inpadoc_jurisdiction_list'])[:100] + \"...\" if len(str(sample['inpadoc_jurisdiction_list'])) > 100 else str(sample['inpadoc_jurisdiction_list'])\n",
    "                    \n",
    "                    print(f\"Inventors: {inventors_sample}\")\n",
    "                    print(f\"Jurisdictions: {jurisdictions_sample}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Export error: {e}\")\n",
    "            return df\n",
    "\n",
    "# ==============================================\n",
    "# MAIN EXECUTION\n",
    "# ==============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # EPO OPS API Credentials\n",
    "    CONSUMER_KEY = \"KEY\"\n",
    "    CONSUMER_SECRET = \"SECRET\"\n",
    "    \n",
    "    # Initialize the EPO Patent Search System\n",
    "    epo_system = EPOPatentSearchSystem(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "   \n",
    "    # Configuration\n",
    "    search_query = \"Alpha-2-macroglobulin\"  # Change this to your desired search\n",
    "    max_results = 25\n",
    "    output_file = f\"EPO_Patent_Dataset_{search_query}.csv\"\n",
    "    \n",
    "    \n",
    "    # Execute comprehensive search\n",
    "    print(f\"\\\\nüöÄ EXECUTING COMPREHENSIVE SEARCH...\")\n",
    "    final_dataset = epo_system.create_comprehensive_dataset(\n",
    "        search_query=search_query,\n",
    "        max_results=max_results,\n",
    "        output_filename=output_file\n",
    "    )\n",
    "    \n",
    "    if final_dataset is not None:\n",
    "        print(f\"\\\\nüéâ SUCCESS! Comprehensive patent dataset created!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\\\n‚ùå Failed to create dataset. Check search query and API connectivity.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6959b160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nüöÄ EXECUTING COMPREHENSIVE SEARCH...\n",
      "üöÄ COMPREHENSIVE EPO PATENT DATA EXTRACTION\n",
      "‚ú® Features: Titles, Inventors, Applicants, Abstracts, Claims, INPADOC Family\n",
      "üîó Format: || separators for all multi-value fields\n",
      "Query: pa = \"CYTONICS CORP\"\n",
      "Max results: 50\n",
      "================================================================================\n",
      "üìù Step 1: Basic patent search...\n",
      "üîç Found 44 patents. Extracting basic data...\n",
      "  Processed 5/44 patents...\n",
      "  Processed 10/44 patents...\n",
      "  Processed 15/44 patents...\n",
      "  Processed 20/44 patents...\n",
      "  Processed 25/44 patents...\n",
      "  Processed 30/44 patents...\n",
      "  Processed 35/44 patents...\n",
      "  Processed 40/44 patents...\n",
      "‚úÖ Extracted basic data for 44 patents\n",
      "\\nüìä Step 2: Getting comprehensive data for 44 patents...\n",
      "  Processing 1/44: US2025270292A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 2/44: US2025205319A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 3/44: US2023250154A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "    ‚úÖ Completed 3/44 patents\n",
      "  Processing 4/44: US2021268078A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 5/44: JP2021080282A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 6/44: US2021147511A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "    ‚úÖ Completed 6/44 patents\n",
      "  Processing 7/44: CA3095010A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 8/44: US2019359690A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 9/44: US2019290741A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "    ‚úÖ Completed 9/44 patents\n",
      "  Processing 10/44: BRPI0920582A2\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "  Processing 11/44: US2019046617A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 12/44: US2017355749A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "    ‚úÖ Completed 12/44 patents\n",
      "  Processing 13/44: AU2017254878A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 14/44: US2017246372A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 15/44: AU2015349782A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "    ‚úÖ Completed 15/44 patents\n",
      "  Processing 16/44: CA2967973A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 17/44: US2016271215A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 18/44: WO2016081834A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "    ‚úÖ Completed 18/44 patents\n",
      "  Processing 19/44: EP3221341A2\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 22 members\n",
      "  Processing 20/44: AU2014312249A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 21/44: CA2922806A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "    ‚úÖ Completed 21/44 patents\n",
      "  Processing 22/44: US2015174221A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 23/44: GB2522561A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 24/44: US2015079194A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "    ‚úÖ Completed 24/44 patents\n",
      "  Processing 25/44: EP3038635A2\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 26/44: WO2015031654A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 12 members\n",
      "  Processing 27/44: CA2865170A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "    ‚úÖ Completed 27/44 patents\n",
      "  Processing 28/44: AU2013222414A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 29/44: GB2503131A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 30/44: EP2827882A1\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "    ‚úÖ Completed 30/44 patents\n",
      "  Processing 31/44: WO2013126587A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 32/44: GB2501611A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 26 members\n",
      "  Processing 33/44: US2013078246A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "    ‚úÖ Completed 33/44 patents\n",
      "  Processing 34/44: CN102246045A\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "  Processing 35/44: KR20110084254A\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "  Processing 36/44: CA2740871A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "    ‚úÖ Completed 36/44 patents\n",
      "  Processing 37/44: AU2008260077A1\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "  Processing 38/44: CA2719550A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "  Processing 39/44: US2010098684A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "    ‚úÖ Completed 39/44 patents\n",
      "  Processing 40/44: EP2353012A1\n",
      "    üìÑ Abstract: ‚úó | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "  Processing 41/44: WO2010045024A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 13 members\n",
      "  Processing 42/44: WO2008150964A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "    ‚úÖ Completed 42/44 patents\n",
      "  Processing 43/44: US2008299110A1\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 6 members\n",
      "  Processing 44/44: WO2007147140A2\n",
      "    üìÑ Abstract: ‚úì | üìã Claims: ‚úó | üë• Family: 3 members\n",
      "\\nüíæ Step 3: Creating comprehensive CSV export...\n",
      "‚úÖ Successfully exported 44 patents to EPO_Patent_Dataset_CYTONICS_CORP.csv\n",
      "Patents with INPADOC family data: 44\n",
      "\\nüìä STATISTICS:\n",
      "Average abstract length: 628 characters\n",
      "Average family size: 17.8 members\n",
      "\\nüéØ SAMPLE || SEPARATOR FORMAT:\n",
      "Patent: US2025270292A1\n",
      "Inventors: HANNA LEWIS‚ÄÇ[US] || LAUGHLIN JOHN DAVID‚ÄÇ[US] || BROWNING SHAWN ROBERT‚ÄÇ[US] || HANNA, Lewis, || LAUGH...\n",
      "Jurisdictions: US || AU || AU || CA || EP || EP || EP || JP || JP || JP || JP || US || US || US || US || US || US |...\n",
      "\\nüéâ SUCCESS! Comprehensive patent dataset created!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# FINAL COMPLETE EPO PATENT SEARCH SYSTEM\n",
    "# Complete solution with all functions integrated\n",
    "# ==============================================\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "# from collections import Counter\n",
    "\n",
    "class EPOPatentSearchSystem:\n",
    "    \"\"\"\n",
    "    Complete EPO Patent Search System with INPADOC family data, abstracts, and claims.\n",
    "    Features:\n",
    "    - Comprehensive patent search\n",
    "    - Title, inventors, applicants extraction\n",
    "    - Abstract and claims retrieval\n",
    "    - INPADOC extended family data\n",
    "    - || separator formatting\n",
    "    - Jurisdiction mapping and family member lists\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, consumer_key: str, consumer_secret: str):\n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = None\n",
    "        self.namespaces = {\n",
    "            'ops': 'http://ops.epo.org',\n",
    "            'ep': 'http://www.epo.org/exchange'\n",
    "        }\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get EPO OPS access token.\"\"\"\n",
    "        url = \"https://ops.epo.org/3.2/auth/accesstoken\"\n",
    "        data = {\"grant_type\": \"client_credentials\"}\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                url, \n",
    "                data=data, \n",
    "                auth=HTTPBasicAuth(self.consumer_key, self.consumer_secret)\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            self.access_token = response.json()[\"access_token\"]\n",
    "            return self.access_token\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Token error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _ensure_token(self):\n",
    "        \"\"\"Ensure we have a valid access token.\"\"\"\n",
    "        if not self.access_token:\n",
    "            return self.get_access_token()\n",
    "        return self.access_token\n",
    "    \n",
    "    def _convert_to_docdb_format(self, publication_number: str):\n",
    "        \"\"\"Convert publication number to DOCDB format.\"\"\"\n",
    "        if publication_number.startswith(('US', 'EP', 'WO', 'JP', 'CN')) and len(publication_number) > 2:\n",
    "            c = publication_number[:2]\n",
    "            rest = publication_number[2:]\n",
    "            for i, char in enumerate(rest):\n",
    "                if char.isalpha():\n",
    "                    n = rest[:i]\n",
    "                    k = rest[i:]\n",
    "                    break\n",
    "            else:\n",
    "                n = rest\n",
    "                k = \"\"\n",
    "            return f\"{c}.{n}.{k}\" if k else f\"{c}.{n}\"\n",
    "        return publication_number\n",
    "    \n",
    "    def search_patents(self, search_query: str, max_results: int = 25):\n",
    "        \"\"\"\n",
    "        Search for patents using EPO OPS API.\n",
    "        \n",
    "        Args:\n",
    "            search_query: EPO search query string\n",
    "            max_results: Maximum number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of patent dictionaries with basic information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return []\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        url = f\"https://ops.epo.org/3.2/rest-services/published-data/search\"\n",
    "        \n",
    "        params = {\n",
    "            \"q\": search_query,\n",
    "            \"Range\": f\"1-{max_results}\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            if response.ok:\n",
    "                root = ET.fromstring(response.content)\n",
    "                \n",
    "                patent_refs = root.findall(\".//ops:publication-reference\", self.namespaces)\n",
    "                patents_data = []\n",
    "                \n",
    "                print(f\"üîç Found {len(patent_refs)} patents. Extracting basic data...\")\n",
    "                \n",
    "                for i, patent_ref in enumerate(patent_refs, 1):\n",
    "                    doc_id = patent_ref.find(\".//ep:document-id[@document-id-type='docdb']\", self.namespaces)\n",
    "                    if doc_id is not None:\n",
    "                        country = doc_id.find(\"ep:country\", self.namespaces)\n",
    "                        number = doc_id.find(\"ep:doc-number\", self.namespaces)\n",
    "                        kind = doc_id.find(\"ep:kind\", self.namespaces)\n",
    "                        date = doc_id.find(\"ep:date\", self.namespaces)\n",
    "                        \n",
    "                        if all(x is not None and x.text for x in [country, number, kind]):\n",
    "                            publication_num = f\"{country.text}{number.text}{kind.text}\"\n",
    "                            pub_date = date.text if date is not None and date.text else \"\"\n",
    "                            \n",
    "                            # Get title if available\n",
    "                            title_elem = patent_ref.find(\".//ep:invention-title[@lang='en']\", self.namespaces)\n",
    "                            title = title_elem.text if title_elem is not None and title_elem.text else \"\"\n",
    "                            \n",
    "                            patent_data = {\n",
    "                                'publication_number': publication_num,\n",
    "                                'country': country.text,\n",
    "                                'doc_number': number.text,\n",
    "                                'kind': kind.text,\n",
    "                                'publication_date': pub_date,\n",
    "                                'title': title,\n",
    "                                'search_index': i\n",
    "                            }\n",
    "                            \n",
    "                            patents_data.append(patent_data)\n",
    "                            \n",
    "                            if i % 5 == 0:\n",
    "                                print(f\"  Processed {i}/{len(patent_refs)} patents...\")\n",
    "                \n",
    "                print(f\"‚úÖ Extracted basic data for {len(patents_data)} patents\")\n",
    "                return patents_data\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Search failed: {response.status_code}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_patent_details(self, publication_number: str, retries: int = 3):\n",
    "        \"\"\"\n",
    "        Get detailed patent information including title, inventors, applicants, abstract, and claims.\n",
    "        \n",
    "        Args:\n",
    "            publication_number: Patent publication number\n",
    "            retries: Number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with detailed patent information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return {}\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        docdb_format = self._convert_to_docdb_format(publication_number)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        # Get bibliographic data (title, inventors, applicants)\n",
    "        biblio_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/biblio\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(biblio_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract title\n",
    "                    title_elem = root.find(\".//ep:invention-title[@lang='en']\", self.namespaces)\n",
    "                    result['title'] = title_elem.text if title_elem is not None else \"\"\n",
    "                    \n",
    "                    # Extract inventors\n",
    "                    inventors = []\n",
    "                    inventor_elems = root.findall(\".//ep:inventor\", self.namespaces)\n",
    "                    for inv in inventor_elems:\n",
    "                        name_elem = inv.find(\".//ep:name\", self.namespaces)\n",
    "                        if name_elem is not None and name_elem.text:\n",
    "                            inventors.append(name_elem.text.strip())\n",
    "                    \n",
    "                    # Extract applicants\n",
    "                    applicants = []\n",
    "                    applicant_elems = root.findall(\".//ep:applicant\", self.namespaces)\n",
    "                    for app in applicant_elems:\n",
    "                        name_elem = app.find(\".//ep:name\", self.namespaces)\n",
    "                        if name_elem is not None and name_elem.text:\n",
    "                            applicants.append(name_elem.text.strip())\n",
    "                    \n",
    "                    result.update({\n",
    "                        'inventors': ' || '.join(inventors) if inventors else '',\n",
    "                        'applicants': ' || '.join(applicants) if applicants else '',\n",
    "                        'inventors_count': len(inventors),\n",
    "                        'applicants_count': len(applicants)\n",
    "                    })\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Biblio failed for {publication_number}: {response.status_code}\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Biblio error for {publication_number} (attempt {attempt + 1}): {e}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # Get abstract\n",
    "        abstract_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/abstract\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(abstract_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract abstract\n",
    "                    abstract_elem = root.find(\".//ep:abstract[@lang='en']\", self.namespaces)\n",
    "                    if abstract_elem is not None:\n",
    "                        # Get all text from abstract, including from paragraphs\n",
    "                        abstract_texts = []\n",
    "                        for p in abstract_elem.findall(\".//ep:p\", self.namespaces):\n",
    "                            if p.text:\n",
    "                                abstract_texts.append(p.text.strip())\n",
    "                        \n",
    "                        if abstract_texts:\n",
    "                            result['abstract'] = ' '.join(abstract_texts)\n",
    "                        elif abstract_elem.text:\n",
    "                            result['abstract'] = abstract_elem.text.strip()\n",
    "                        else:\n",
    "                            result['abstract'] = \"\"\n",
    "                    else:\n",
    "                        result['abstract'] = \"\"\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    result['abstract'] = \"\"\n",
    "                    if response.status_code != 404:  # 404 is normal for missing abstracts\n",
    "                        print(f\"‚ö†Ô∏è Abstract failed for {publication_number}: {response.status_code}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                result['abstract'] = \"\"\n",
    "                break\n",
    "        \n",
    "        # Get claims\n",
    "        claims_url = f\"https://ops.epo.org/3.2/rest-services/published-data/publication/docdb/{docdb_format}/claims\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(claims_url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Extract claims\n",
    "                    claims_texts = []\n",
    "                    claim_elems = root.findall(\".//ep:claim[@lang='en']\", self.namespaces)\n",
    "                    for claim in claim_elems:\n",
    "                        claim_num = claim.get('num', '')\n",
    "                        claim_text = \"\"\n",
    "                        \n",
    "                        # Get text from paragraphs within claim\n",
    "                        for p in claim.findall(\".//ep:claim-text\", self.namespaces):\n",
    "                            if p.text:\n",
    "                                claim_text += p.text.strip() + \" \"\n",
    "                        \n",
    "                        if claim_text.strip():\n",
    "                            claims_texts.append(f\"Claim {claim_num}: {claim_text.strip()}\")\n",
    "                    \n",
    "                    if claims_texts:\n",
    "                        result['claims'] = ' || '.join(claims_texts[:5])  # Limit to first 5 claims\n",
    "                    else:\n",
    "                        result['claims'] = \"\"\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    result['claims'] = \"\"\n",
    "                    if response.status_code != 404:  # 404 is normal for missing claims\n",
    "                        print(f\"‚ö†Ô∏è Claims failed for {publication_number}: {response.status_code}\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                result['claims'] = \"\"\n",
    "                break\n",
    "        \n",
    "        # Set defaults for missing data\n",
    "        default_fields = ['title', 'inventors', 'applicants', 'abstract', 'claims']\n",
    "        for field in default_fields:\n",
    "            if field not in result:\n",
    "                result[field] = \"\"\n",
    "        \n",
    "        if 'inventors_count' not in result:\n",
    "            result['inventors_count'] = 0\n",
    "        if 'applicants_count' not in result:\n",
    "            result['applicants_count'] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_inpadoc_family_data(self, publication_number: str, retries: int = 3):\n",
    "        \"\"\"\n",
    "        Get INPADOC extended family data with enhanced formatting.\n",
    "        \n",
    "        Args:\n",
    "            publication_number: Patent publication number\n",
    "            retries: Number of retry attempts\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with INPADOC family information\n",
    "        \"\"\"\n",
    "        if not self._ensure_token():\n",
    "            return {}\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {self.access_token}\", \"Accept\": \"application/xml\"}\n",
    "        docdb_format = self._convert_to_docdb_format(publication_number)\n",
    "        \n",
    "        url = f\"https://ops.epo.org/3.2/rest-services/family/publication/docdb/{docdb_format}\"\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=30)\n",
    "                if response.ok:\n",
    "                    root = ET.fromstring(response.content)\n",
    "                    \n",
    "                    # Get family information\n",
    "                    family_elem = root.find(\".//ops:patent-family\", self.namespaces)\n",
    "                    total_count = family_elem.get('total-result-count', '0') if family_elem is not None else '0'\n",
    "                    \n",
    "                    # Get all family members\n",
    "                    family_members = root.findall(\".//ops:family-member\", self.namespaces)\n",
    "                    \n",
    "                    # Collect jurisdictions and members\n",
    "                    jurisdiction_list = []\n",
    "                    all_family_members = []\n",
    "                    \n",
    "                    for member in family_members:\n",
    "                        # publication-reference is in the ep namespace\n",
    "                        pub_ref = member.find(\".//ep:publication-reference\", self.namespaces)\n",
    "                        if pub_ref is not None:\n",
    "                            # document-id elements are also in ep namespace\n",
    "                            doc_id = pub_ref.find(\".//ep:document-id[@document-id-type='docdb']\", self.namespaces)\n",
    "                            if doc_id is not None:\n",
    "                                country = doc_id.find(\"ep:country\", self.namespaces)\n",
    "                                number = doc_id.find(\"ep:doc-number\", self.namespaces)\n",
    "                                kind = doc_id.find(\"ep:kind\", self.namespaces)\n",
    "                                date = doc_id.find(\"ep:date\", self.namespaces)\n",
    "                                \n",
    "                                if all(x is not None and x.text for x in [country, number, kind]):\n",
    "                                    country_code = country.text\n",
    "                                    pub_num = f\"{country_code}{number.text}{kind.text}\"\n",
    "                                    pub_date = date.text if date is not None and date.text else \"\"\n",
    "                                    \n",
    "                                    # Add to jurisdiction list for each occurrence\n",
    "                                    jurisdiction_list.append(country_code)\n",
    "                                    \n",
    "                                    all_family_members.append({\n",
    "                                        'publication': pub_num,\n",
    "                                        'country': country_code,\n",
    "                                        'date': pub_date\n",
    "                                    })\n",
    "                    \n",
    "                    # Create jurisdiction string with || separator (showing each occurrence)\n",
    "                    jurisdiction_string = ' || '.join(jurisdiction_list)\n",
    "                    \n",
    "                    # Create family members string with || separator\n",
    "                    family_members_string = ' || '.join([member['publication'] for member in all_family_members])\n",
    "                    \n",
    "                    return {\n",
    "                        'inpadoc_family_size': len(all_family_members),\n",
    "                        'inpadoc_jurisdictions_count': len(set(jurisdiction_list)),\n",
    "                        'inpadoc_jurisdiction_list': jurisdiction_string,\n",
    "                        'inpadoc_family_members': family_members_string\n",
    "                    }\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Family failed for {publication_number}: {response.status_code}\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Family error for {publication_number} (attempt {attempt + 1}): {e}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def create_comprehensive_dataset(self, search_query: str, max_results: int = 25, output_filename: str = None):\n",
    "        \"\"\"\n",
    "        Create comprehensive patent dataset with all features.\n",
    "        \n",
    "        Args:\n",
    "            search_query: EPO search query string\n",
    "            max_results: Maximum number of patents to process\n",
    "            output_filename: Output CSV filename (auto-generated if None)\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame with comprehensive patent data\n",
    "        \"\"\"\n",
    "        if output_filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"comprehensive_patent_data_{timestamp}.csv\"\n",
    "        \n",
    "        print(f\"üöÄ COMPREHENSIVE EPO PATENT DATA EXTRACTION\")\n",
    "        print(f\"‚ú® Features: Titles, Inventors, Applicants, Abstracts, Claims, INPADOC Family\")\n",
    "        print(f\"üîó Format: || separators for all multi-value fields\")\n",
    "        print(f\"Query: {search_query}\")\n",
    "        print(f\"Max results: {max_results}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Step 1: Basic search\n",
    "        print(\"üìù Step 1: Basic patent search...\")\n",
    "        basic_patents = self.search_patents(search_query, max_results)\n",
    "        \n",
    "        if not basic_patents:\n",
    "            print(\"‚ùå No patents found in basic search\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Get comprehensive data for each patent\n",
    "        print(f\"\\\\nüìä Step 2: Getting comprehensive data for {len(basic_patents)} patents...\")\n",
    "        comprehensive_data = []\n",
    "        \n",
    "        for i, patent in enumerate(basic_patents, 1):\n",
    "            pub_num = patent['publication_number']\n",
    "            print(f\"  Processing {i}/{len(basic_patents)}: {pub_num}\")\n",
    "            \n",
    "            # Start with basic data\n",
    "            patent_data = patent.copy()\n",
    "            \n",
    "            # Get detailed data (title, inventors, applicants, abstract, claims)\n",
    "            detailed_data = self.get_patent_details(pub_num)\n",
    "            patent_data.update(detailed_data)\n",
    "            \n",
    "            # Get INPADOC family data\n",
    "            family_data = self.get_inpadoc_family_data(pub_num)\n",
    "            patent_data.update(family_data)\n",
    "            \n",
    "            # Show progress\n",
    "            abstract_status = \"‚úì\" if detailed_data.get('abstract', '') else \"‚úó\"\n",
    "            claims_status = \"‚úì\" if detailed_data.get('claims', '') else \"‚úó\"\n",
    "            family_size = family_data.get('inpadoc_family_size', 0)\n",
    "            \n",
    "            print(f\"    üìÑ Abstract: {abstract_status} | üìã Claims: {claims_status} | üë• Family: {family_size} members\")\n",
    "            \n",
    "            comprehensive_data.append(patent_data)\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.8)\n",
    "            \n",
    "            if i % 3 == 0:\n",
    "                print(f\"    ‚úÖ Completed {i}/{len(basic_patents)} patents\")\n",
    "        \n",
    "        # Step 3: Create DataFrame and export\n",
    "        print(f\"\\\\nüíæ Step 3: Creating comprehensive CSV export...\")\n",
    "        df = pd.DataFrame(comprehensive_data)\n",
    "        \n",
    "        # Define complete column structure\n",
    "        expected_columns = [\n",
    "            'publication_number', 'country', 'doc_number', 'kind', 'publication_date',\n",
    "            'title', 'abstract', 'claims',\n",
    "            'inventors', 'applicants', 'inventors_count', 'applicants_count',\n",
    "            'inpadoc_family_size', 'inpadoc_jurisdictions_count', \n",
    "            'inpadoc_jurisdiction_list', 'inpadoc_family_members', 'search_index'\n",
    "        ]\n",
    "        \n",
    "        for col in expected_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = ''\n",
    "        \n",
    "        # Reorder columns\n",
    "        df = df[expected_columns]\n",
    "        \n",
    "        # Export to CSV\n",
    "        try:\n",
    "            df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"‚úÖ Successfully exported {len(df)} patents to {output_filename}\")\n",
    "            \n",
    "            \n",
    "            # INPADOC family statistics\n",
    "            patents_with_family = len(df[df['inpadoc_family_size'] > 0])\n",
    "            print(f\"Patents with INPADOC family data: {patents_with_family}\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                avg_abstract_length = df[df['abstract'] != '']['abstract'].str.len().mean() if len(df[df['abstract'] != '']) > 0 else 0\n",
    "                avg_family_size = df['inpadoc_family_size'].mean()\n",
    "                \n",
    "                print(f\"\\\\nüìä STATISTICS:\")\n",
    "                print(f\"Average abstract length: {avg_abstract_length:.0f} characters\")\n",
    "                print(f\"Average family size: {avg_family_size:.1f} members\")\n",
    "                \n",
    "                # Show sample format\n",
    "                print(f\"\\\\nüéØ SAMPLE || SEPARATOR FORMAT:\")\n",
    "                if len(df) > 0:\n",
    "                    sample = df.iloc[0]\n",
    "                    print(f\"Patent: {sample['publication_number']}\")\n",
    "                    \n",
    "                    # Show sample data\n",
    "                    inventors_sample = str(sample['inventors'])[:100] + \"...\" if len(str(sample['inventors'])) > 100 else str(sample['inventors'])\n",
    "                    jurisdictions_sample = str(sample['inpadoc_jurisdiction_list'])[:100] + \"...\" if len(str(sample['inpadoc_jurisdiction_list'])) > 100 else str(sample['inpadoc_jurisdiction_list'])\n",
    "                    \n",
    "                    print(f\"Inventors: {inventors_sample}\")\n",
    "                    print(f\"Jurisdictions: {jurisdictions_sample}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Export error: {e}\")\n",
    "            return df\n",
    "\n",
    "# ==============================================\n",
    "# MAIN EXECUTION\n",
    "# ==============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # EPO OPS API Credentials\n",
    "    CONSUMER_KEY = \"KEY\"\n",
    "    CONSUMER_SECRET = \"SECRET\"\n",
    "    \n",
    "    # Initialize the EPO Patent Search System\n",
    "    epo_system = EPOPatentSearchSystem(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "   \n",
    "    # Configuration\n",
    "    search_query = 'pa = \"CYTONICS CORP\"'  # Change this to your desired search\n",
    "    max_results = 50\n",
    "    output_file = \"EPO_Patent_Dataset_CYTONICS_CORP.csv\"\n",
    "    \n",
    "    \n",
    "    # Execute comprehensive search\n",
    "    print(f\"\\\\nüöÄ EXECUTING COMPREHENSIVE SEARCH...\")\n",
    "    final_dataset = epo_system.create_comprehensive_dataset(\n",
    "        search_query=search_query,\n",
    "        max_results=max_results,\n",
    "        output_filename=output_file\n",
    "    )\n",
    "    \n",
    "    if final_dataset is not None:\n",
    "        print(f\"\\\\nüéâ SUCCESS! Comprehensive patent dataset created!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\\\n‚ùå Failed to create dataset. Check search query and API connectivity.\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
